{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Función para instalar OpenJDK 8 si no está instalado previamente.\n",
        "def install_java():\n",
        "    # Verifica si la ruta del JDK existe.\n",
        "    if not os.path.exists('/usr/lib/jvm/java-8-openjdk-amd64'):\n",
        "        print(\"Instalando OpenJDK 8...\")\n",
        "        # Comando para instalar Java en modo silencioso.\n",
        "        !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "        print(\"OpenJDK 8 instalado correctamente.\")\n",
        "    else:\n",
        "        print(\"OpenJDK 8 ya está instalado.\")\n",
        "\n",
        "\n",
        "\n",
        "# Función para descargar Apache Spark solo si no está ya descargado.\n",
        "def download_spark():\n",
        "    # URL y nombre del archivo comprimido de Spark.\n",
        "    spark_url = \"https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si el archivo comprimido ya existe.\n",
        "    if not os.path.exists(spark_tar):\n",
        "        print(\"Descargando Apache Spark...\")\n",
        "        # Comando para descargar el archivo desde la URL.\n",
        "        !wget -q $spark_url\n",
        "        print(\"Descarga completa.\")\n",
        "    else:\n",
        "        print(\"El archivo de Apache Spark ya está descargado.\")\n",
        "\n",
        "\n",
        "\n",
        "# Función para descomprimir el archivo de Apache Spark solo si no está descomprimido.\n",
        "def extract_spark():\n",
        "    # Nombre de la carpeta descomprimida.\n",
        "    spark_dir = \"spark-3.4.3-bin-hadoop3\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si la carpeta descomprimida ya existe.\n",
        "    if not os.path.exists(spark_dir):\n",
        "        print(\"Descomprimiendo Apache Spark...\")\n",
        "        # Comando para descomprimir el archivo.\n",
        "        !tar xf $spark_tar\n",
        "        print(\"Apache Spark descomprimido.\")\n",
        "    else:\n",
        "        print(\"La carpeta de Apache Spark ya existe.\")\n",
        "\n",
        "\n",
        "\n",
        "# Función para configurar las variables de entorno necesarias para Spark.\n",
        "def set_environment_variables():\n",
        "    # Establece la ruta de JAVA_HOME y SPARK_HOME.\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\"\n",
        "    print(\"Variables de entorno configuradas.\")\n",
        "\n",
        "\n",
        "\n",
        "# Función para verificar si un paquete de Python ya está instalado.\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def is_package_installed(package_name):\n",
        "    try:\n",
        "        # Ejecuta el comando `pip show` para verificar si el paquete está instalado.\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"show\", package_name],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL\n",
        "        )\n",
        "        return True\n",
        "    except subprocess.CalledProcessError:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "# Función para instalar librerías de Python necesarias (findspark y pyspark).\n",
        "def install_python_libraries():\n",
        "    # Verifica e instala findspark.\n",
        "    if not is_package_installed(\"findspark\"):\n",
        "        print(\"Instalando findspark...\")\n",
        "        !pip install -q findspark\n",
        "    else:\n",
        "        print(\"findspark ya está instalado.\")\n",
        "\n",
        "    # Verifica e instala pyspark.\n",
        "    if not is_package_installed(\"pyspark\"):\n",
        "        print(\"Instalando pyspark...\")\n",
        "        !pip install -q pyspark\n",
        "    else:\n",
        "        print(\"pyspark ya está instalado.\")\n",
        "\n",
        "\n",
        "\n",
        "install_java()                # Instala OpenJDK 8\n",
        "download_spark()              # Descarga Apache Spark\n",
        "extract_spark()               # Descomprime Apache Spark\n",
        "set_environment_variables()   # Configura las variables de entorno\n",
        "install_python_libraries()    # Instala las librerías de Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXwui0oU2E-x",
        "outputId": "48f9084c-8718-46b2-8019-895f1fb9d326"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenJDK 8 ya está instalado.\n",
            "El archivo de Apache Spark ya está descargado.\n",
            "La carpeta de Apache Spark ya existe.\n",
            "Variables de entorno configuradas.\n",
            "findspark ya está instalado.\n",
            "pyspark ya está instalado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Crear una sesion en Spark**"
      ],
      "metadata": {
        "id": "t5i-OfFAdt6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la biblioteca findspark, que ayuda a configurar PySpark correctamente en el entorno de ejecución\n",
        "import findspark\n",
        "\n",
        "# Inicializar findspark para establecer las variables necesarias de PySpark\n",
        "findspark.init()\n",
        "\n",
        "# Importar SparkSession desde la biblioteca pyspark.sql\n",
        "# SparkSession es la entrada principal para trabajar con DataFrames en PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Crear o obtener una SparkSession\n",
        "# Esto inicializa un entorno de Spark si no existe uno, o reutiliza uno existente\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Obtener el contexto de Spark (SparkContext) desde la SparkSession\n",
        "# SparkContext es la entrada principal para trabajar con RDDs en PySpark\n",
        "sc = spark.sparkContext\n"
      ],
      "metadata": {
        "id": "eztf5DxddjDm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "RP6dgxU9ugJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Teoría sobre las Variables Broadcast en Spark**\n",
        "\n",
        "En Spark, las variables **Broadcast** son una herramienta importante para optimizar el rendimiento de las aplicaciones distribuidas cuando se necesitan compartir datos de manera eficiente entre las distintas particiones de un clúster. Una **variable Broadcast** es un mecanismo que permite distribuir de manera eficiente y en solo una vez, grandes conjuntos de datos o variables a todos los nodos de un clúster, sin necesidad de enviarlos repetidamente durante cada tarea.\n",
        "\n",
        "### ¿Qué son las Variables Broadcast?\n",
        "\n",
        "Las variables Broadcast son **datos de solo lectura** que son compartidos entre todas las tareas en todas las particiones de los nodos de un clúster. Son útiles cuando tienes un conjunto de datos pequeño o mediano que se necesita en todas las tareas de un trabajo, como una tabla de búsqueda, una lista de configuraciones o parámetros, o un modelo entrenado que debe ser utilizado por cada nodo del clúster.\n",
        "\n",
        "### Beneficios de las Variables Broadcast\n",
        "\n",
        "1. **Reducción del Coste de Comunicación**:\n",
        "   - Sin las variables broadcast, si un conjunto de datos es necesario en varias particiones, Spark tendría que enviar una copia de ese conjunto de datos a cada partición de forma repetida. Esto genera una gran sobrecarga de red. Al usar variables Broadcast, el conjunto de datos solo se envía una vez y se distribuye de manera eficiente a todos los nodos.\n",
        "   \n",
        "2. **Mejora del Rendimiento**:\n",
        "   - Las variables Broadcast permiten que los datos sean **inmutables** y sean **solo lectura**, lo que hace que puedan ser fácilmente cacheados y compartidos entre los nodos sin necesidad de replicarlos varias veces, mejorando así el rendimiento en trabajos distribuidos.\n",
        "\n",
        "3. **Uso Eficiente de la Memoria**:\n",
        "   - Al ser distribuidas solo una vez, se minimiza el uso de memoria en cada nodo y se optimiza el proceso de ejecución.\n",
        "\n",
        "### ¿Cómo Funcionan las Variables Broadcast?\n",
        "\n",
        "1. **Creación**:\n",
        "   - Una variable Broadcast se crea utilizando el método `sc.broadcast()`, donde `sc` es el `SparkContext` que inicializa la sesión de Spark.\n",
        "   \n",
        "2. **Acceso a los Datos**:\n",
        "   - Una vez que se crea la variable Broadcast, el acceso a los datos se realiza a través del método `.value`, que devuelve el contenido de la variable.\n",
        "\n",
        "3. **Distribución**:\n",
        "   - Una vez que la variable es \"broadcasted\", todos los nodos del clúster pueden acceder a esa variable de forma local sin necesidad de acceder a los datos centralmente.\n",
        "\n",
        "### Ejemplo de Uso:"
      ],
      "metadata": {
        "id": "ilMpr5ByQpgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un conjunto de datos a compartir entre las tareas\n",
        "broadcast_var = sc.broadcast([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Usar la variable broadcast en una función que se aplica a cada partición\n",
        "rdd = sc.parallelize([10, 20, 30, 40])\n",
        "result = rdd.map(lambda x: x + sum(broadcast_var.value))\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(result.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf_hvxTuQtdy",
        "outputId": "3d2ebe9d-9119-4cb6-e479-3a64cfac91bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31, 41, 51, 61]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "En este ejemplo, la lista `[1, 2, 3, 4]` se distribuye a todas las particiones, y luego es utilizada dentro de una operación `map()` sobre el RDD sin que sea necesario enviarla repetidamente a cada partición.\n",
        "\n",
        "### Casos de Uso Comunes:\n",
        "- **Tablas de búsqueda**: Cuando necesitas usar una tabla estática o un conjunto de parámetros pequeños en cada tarea de Spark.\n",
        "- **Modelos entrenados**: Un modelo de machine learning preentrenado que debe ser utilizado en todas las particiones sin necesidad de enviarlo repetidamente.\n",
        "- **Datos estáticos o de configuración**: Información que no cambia durante el procesamiento y que debe ser accesible en todos los nodos.\n",
        "\n",
        "### Consideraciones:\n",
        "- Las variables Broadcast deben ser **inmutables** (no deben modificarse una vez que se han \"broadcasted\").\n",
        "- **Solo deben usarse para conjuntos de datos pequeños a medianos**: Si la cantidad de datos es muy grande, el uso de Broadcast puede no ser eficiente y podría consumir mucha memoria en los nodos.\n",
        "\n",
        "Las variables Broadcast son una forma de optimizar el uso de recursos en aplicaciones distribuidas, mejorando la eficiencia de las operaciones que requieren compartir información entre varias tareas y particiones."
      ],
      "metadata": {
        "id": "NSKstQDVQsgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uso de unpersist() para Liberar Memoria en PySpark**\n",
        "\n",
        "El método `unpersist()` se utiliza cuando **has persistido un RDD** o **DataFrame** en memoria o en disco y deseas liberar los recursos que han sido reservados para ello.\n",
        "\n",
        "En PySpark, puedes persistir datos de un RDD o DataFrame en memoria utilizando el método `.persist()`, lo que significa que los datos serán almacenados en memoria y se evitará el re-calculo de esos datos cuando se vuelvan a utilizar. Si ya no necesitas esos datos en memoria y deseas liberar la memoria, puedes usar `unpersist()`.\n",
        "\n",
        "### Ejemplo práctico con `unpersist()`:"
      ],
      "metadata": {
        "id": "J1dZOXSpewi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar la variable Broadcast\n",
        "broadcast_var.unpersist()"
      ],
      "metadata": {
        "id": "CM4pM6TSXGQB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicación:\n",
        "\n",
        "- **`broadcast_var.unpersist()`**: Este método se usa para liberar la memoria en los nodos del clúster donde la variable Broadcast ha sido almacenada. Al llamar a `unpersist()`, estamos indicando que ya no necesitamos más la variable Broadcast y queremos liberar los recursos asociados con ella.\n",
        "\n",
        "### ¿Por qué se debe hacer?\n",
        "\n",
        "- **Liberar recursos**: Las variables Broadcast se distribuyen a todos los nodos del clúster, lo que implica que ocupan memoria en cada uno de esos nodos. Si ya no necesitamos esa variable, es recomendable liberarla para evitar que ocupe memoria innecesaria.\n",
        "- **Eficiencia**: Si no se hace esto, la variable Broadcast continuará ocupando memoria incluso después de que ya no sea necesaria, lo que podría afectar el rendimiento de otras tareas o procesos que requieren memoria.\n",
        "- **Práctica recomendada**: Es una buena práctica liberar cualquier recurso, como variables Broadcast, cuando ya no son necesarios para asegurar un uso eficiente de la memoria y evitar fugas de memoria.\n",
        "\n",
        "De esta forma, aseguras que los recursos se gestionan adecuadamente en el clúster."
      ],
      "metadata": {
        "id": "S2QmHSzZXKYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Código para eliminar una variable Broadcast en PySpark**\n",
        "\n",
        "Para eliminar una variable Broadcast, usamos el método `destroy()` que está disponible para las variables broadcast. Aquí tienes el código:"
      ],
      "metadata": {
        "id": "cxcahRzGTLQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código para destruir la variable Broadcast:"
      ],
      "metadata": {
        "id": "RW0TcHmYczOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Destruir la variable Broadcast\n",
        "broadcast_var.destroy()"
      ],
      "metadata": {
        "id": "E9vCKO36c1RQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicación:\n",
        "\n",
        "- **`broadcast_var.destroy()`**: Este método destruye la variable Broadcast de manera explícita. Al hacerlo, se libera cualquier referencia interna que Spark pueda estar utilizando para la variable, asegurando que los datos asociados con ella sean eliminados de manera más completa.\n",
        "\n",
        "### ¿Por qué se debe hacer?\n",
        "\n",
        "- **Liberación completa de recursos**: Aunque `unpersist()` libera la memoria, `destroy()` asegura que la variable Broadcast sea eliminada por completo, lo que significa que no quedará ninguna referencia en el sistema, liberando todos los recursos asociados.\n",
        "- **Evitar fugas de memoria**: Al destruir la variable Broadcast, te aseguras de que no quede memoria ocupada innecesaria en los nodos del clúster. Esto es especialmente importante en entornos de producción donde se maneja una gran cantidad de datos.\n",
        "- **Práctica recomendada**: Llamar a `destroy()` es útil cuando sabes que la variable Broadcast ya no se va a utilizar en el futuro, asegurando una limpieza completa y eficiente de los recursos.\n",
        "\n",
        "Usar `destroy()` es una medida más fuerte que `unpersist()`, ya que garantiza que la variable y los datos asociados sean eliminados de forma definitiva."
      ],
      "metadata": {
        "id": "AcvzM-1fc-HZ"
      }
    }
  ]
}