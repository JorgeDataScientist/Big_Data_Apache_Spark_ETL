{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso a Paso Para Realizar Instalacion de Apache Spark en Colab**\n",
        "# **🤯**\n",
        "---"
      ],
      "metadata": {
        "id": "aLApO7WKO3kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "z3COh-nXrene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Función para instalar OpenJDK 8\n"
      ],
      "metadata": {
        "id": "dLWqeDnhldNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para instalar OpenJDK 8 si no está instalado previamente.\n",
        "def install_java():\n",
        "    # Verifica si la ruta del JDK existe.\n",
        "    if not os.path.exists('/usr/lib/jvm/java-8-openjdk-amd64'):\n",
        "        print(\"Instalando OpenJDK 8...\")\n",
        "        # Comando para instalar Java en modo silencioso.\n",
        "        !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "        print(\"OpenJDK 8 instalado correctamente.\")\n",
        "    else:\n",
        "        print(\"OpenJDK 8 ya está instalado.\")"
      ],
      "metadata": {
        "id": "ocwoPb91loee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Función para descargar Apache Spark"
      ],
      "metadata": {
        "id": "avmuQpDIlrk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para descargar Apache Spark solo si no está ya descargado.\n",
        "def download_spark():\n",
        "    # URL y nombre del archivo comprimido de Spark.\n",
        "    spark_url = \"https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si el archivo comprimido ya existe.\n",
        "    if not os.path.exists(spark_tar):\n",
        "        print(\"Descargando Apache Spark...\")\n",
        "        # Comando para descargar el archivo desde la URL.\n",
        "        !wget -q $spark_url\n",
        "        print(\"Descarga completa.\")\n",
        "    else:\n",
        "        print(\"El archivo de Apache Spark ya está descargado.\")"
      ],
      "metadata": {
        "id": "Wt6hZEyulx52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Función para descomprimir Apache Spark"
      ],
      "metadata": {
        "id": "8Jgxtdhal1MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para descomprimir el archivo de Apache Spark solo si no está descomprimido.\n",
        "def extract_spark():\n",
        "    # Nombre de la carpeta descomprimida.\n",
        "    spark_dir = \"spark-3.4.3-bin-hadoop3\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si la carpeta descomprimida ya existe.\n",
        "    if not os.path.exists(spark_dir):\n",
        "        print(\"Descomprimiendo Apache Spark...\")\n",
        "        # Comando para descomprimir el archivo.\n",
        "        !tar xf $spark_tar\n",
        "        print(\"Apache Spark descomprimido.\")\n",
        "    else:\n",
        "        print(\"La carpeta de Apache Spark ya existe.\")"
      ],
      "metadata": {
        "id": "ixXnx5VBl5mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Función para configurar variables de entorno"
      ],
      "metadata": {
        "id": "CUL79waXl8G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para configurar las variables de entorno necesarias para Spark.\n",
        "def set_environment_variables():\n",
        "    # Establece la ruta de JAVA_HOME y SPARK_HOME.\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\"\n",
        "    print(\"Variables de entorno configuradas.\")"
      ],
      "metadata": {
        "id": "9Z1obZ1al_Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Función para verificar si un paquete está instalado"
      ],
      "metadata": {
        "id": "5lZztVgNmErm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para verificar si un paquete de Python ya está instalado.\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def is_package_installed(package_name):\n",
        "    try:\n",
        "        # Ejecuta el comando `pip show` para verificar si el paquete está instalado.\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"show\", package_name],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL\n",
        "        )\n",
        "        return True\n",
        "    except subprocess.CalledProcessError:\n",
        "        return False"
      ],
      "metadata": {
        "id": "l7iVbLSFmL_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Función para instalar findspark y pyspark"
      ],
      "metadata": {
        "id": "pGJ6jvDVmSBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para instalar librerías de Python necesarias (findspark y pyspark).\n",
        "def install_python_libraries():\n",
        "    # Verifica e instala findspark.\n",
        "    if not is_package_installed(\"findspark\"):\n",
        "        print(\"Instalando findspark...\")\n",
        "        !pip install -q findspark\n",
        "    else:\n",
        "        print(\"findspark ya está instalado.\")\n",
        "\n",
        "    # Verifica e instala pyspark.\n",
        "    if not is_package_installed(\"pyspark\"):\n",
        "        print(\"Instalando pyspark...\")\n",
        "        !pip install -q pyspark\n",
        "    else:\n",
        "        print(\"pyspark ya está instalado.\")"
      ],
      "metadata": {
        "id": "iFauCFnDmT7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Llamar a las funciones**"
      ],
      "metadata": {
        "id": "5aOgcvM-mZam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install_java()                # Instala OpenJDK 8\n",
        "download_spark()              # Descarga Apache Spark\n",
        "extract_spark()               # Descomprime Apache Spark\n",
        "set_environment_variables()   # Configura las variables de entorno\n",
        "install_python_libraries()    # Instala las librerías de Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9NdiQLAmfPW",
        "outputId": "8745a976-d8d8-49aa-e6d8-988c90fa992f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenJDK 8 ya está instalado.\n",
            "El archivo de Apache Spark ya está descargado.\n",
            "La carpeta de Apache Spark ya existe.\n",
            "Variables de entorno configuradas.\n",
            "findspark ya está instalado.\n",
            "pyspark ya está instalado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "O24lzVStmn72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Verificar la Instalacion"
      ],
      "metadata": {
        "id": "qZTO7-eNaT0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la biblioteca findspark\n",
        "import findspark\n",
        "\n",
        "# Inicializamos findspark para configurar las rutas necesarias para Spark\n",
        "findspark.init()\n",
        "\n",
        "# Importamos SparkSession desde pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Creamos una instancia de SparkSession\n",
        "# - `master(\"local[*]\")`: Ejecuta Spark en modo local usando todos los núcleos disponibles.\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "LFws1CIIVcVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo con varias columnas\n",
        "# - `datos`: Es una lista de tuplas, donde cada tupla representa una fila del DataFrame.\n",
        "# - `columnas`: Especifica los nombres de las columnas.\n",
        "datos = [\n",
        "    (\"Jorge Luis\", 46, \"Científico de Datos\"),\n",
        "    (\"Maria Gabriela\", 41, \"Administrador\"),\n",
        "    (\"Barbara\", 10, \"Pintor\"),\n",
        "    (\"Marco Antonio\", 5, \"Pre-Esccolar\"),\n",
        "    (\"Luis\", 74, \"Escritor\")\n",
        "]\n",
        "columnas = [\"Nombre\", \"Edad\", \"Profesión\"]\n",
        "\n",
        "# Creamos el DataFrame utilizando los datos y las columnas especificadas\n",
        "df = spark.createDataFrame(datos, columnas)\n",
        "\n",
        "# Mostramos el contenido del DataFrame\n",
        "# - `show()`: Muestra las primeras filas del DataFrame.\n",
        "# - `truncate=False`: Evita truncar los valores largos en las columnas.\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Ru8UsGXFZA",
        "outputId": "bf231364-6b2a-4fd0-de43-ea08ab9c76e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+-------------------+\n",
            "|Nombre        |Edad|Profesión          |\n",
            "+--------------+----+-------------------+\n",
            "|Jorge Luis    |46  |Científico de Datos|\n",
            "|Maria Gabriela|41  |Administrador      |\n",
            "|Barbara       |10  |Pintor             |\n",
            "|Marco Antonio |5   |Pre-Esccolar       |\n",
            "|Luis          |74  |Escritor           |\n",
            "+--------------+----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 👌 🆗 **Culminado**\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "3GIDgjm2o_CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operaciones principales en RDD**\n",
        "\n",
        "# 🔖"
      ],
      "metadata": {
        "id": "kP5vxailckCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "Un Resilient Distributed Dataset (RDD) en Apache Spark es una colección distribuida de elementos que puede ser procesada en paralelo. Los RDD ofrecen dos tipos principales de operaciones: transformaciones y acciones. En este documento, nos enfocaremos en las transformaciones y las clasificaremos en diferentes categorías según su naturaleza.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "O4_lkmLOoOEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Iniciar Sesion de Spark\""
      ],
      "metadata": {
        "id": "IH8lZhVavyNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "n3OoxqsgvoWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 1. Transformaciones generales\n",
        "\n",
        "Las transformaciones generales permiten modificar o reorganizar los datos dentro de un RDD. Estas incluyen:"
      ],
      "metadata": {
        "id": "xBsNHx0UwBby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Dividir los elementos de entrada**\n",
        "\n",
        "Esta transformación se utiliza para dividir los elementos de un RDD en subcomponentes. Una operación común es `flatMap`, que genera múltiples salidas para cada entrada."
      ],
      "metadata": {
        "id": "RaAkbrNYomz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([\"hola mundo\", \"aprendiendo Spark\", \"RDD en acción\"])\n",
        "resultado = rdd.flatMap(lambda linea: linea.split(\" \"))\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kRHRx7duXrp",
        "outputId": "f896e633-ad88-4f4e-e4d6-1e51f06887b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'mundo', 'aprendiendo', 'Spark', 'RDD', 'en', 'acción']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Filtrar elementos**\n",
        "\n",
        "La operación `filter` permite seleccionar sólo los elementos que cumplen una condición determinada."
      ],
      "metadata": {
        "id": "bngLC75YpETF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "resultado = rdd.filter(lambda x: x % 2 == 0)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhTFquoNxGUb",
        "outputId": "244f1a13-d8ba-44a8-daa3-4a7a7b2f4a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **Realizar cálculos**\n",
        "\n",
        "Se pueden realizar transformaciones matemáticas como operaciones aritméticas utilizando `map`."
      ],
      "metadata": {
        "id": "-jviueaJpJNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "resultado = rdd.map(lambda x: x ** 2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Hj_oCdxKsJ",
        "outputId": "4173a6c3-4e31-460d-fecc-5be080e95acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4vdHmsDwpqIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Transformaciones matemáticas\n",
        "\n",
        "Estas transformaciones están diseñadas para realizar operaciones aritméticas o algebraicas sobre los datos."
      ],
      "metadata": {
        "id": "AZ242Dq0p7IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Suma acumulativa**\n",
        "\n",
        "Utilizando `reduceByKey`, se puede sumar valores asociados con claves específicas."
      ],
      "metadata": {
        "id": "dq3hvzvNqDZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd.reduceByKey(lambda x, y: x + y)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKZysqftxWUg",
        "outputId": "83c7c11e-6dec-42bc-b27d-3bff1539e94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 6), ('a', 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Cálculo promedio**\n",
        "\n",
        "Podemos calcular el promedio agrupando valores por clave y dividiendo la suma por el conteo."
      ],
      "metadata": {
        "id": "3O98-jXrqGuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd\\\n",
        "    .mapValues(lambda x: (x, 1))\\\n",
        "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
        "    .mapValues(lambda x: x[0] / x[1])\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I3B_niBxb0C",
        "outputId": "f2f73ef8-4857-48ee-b0f2-2abac17cb4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 3.0), ('a', 2.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. Transformaciones de conjunto o relacionales\n",
        "\n",
        "Estas transformaciones operan en conjuntos de datos y se utilizan para relaciones como uniones, intersecciones o diferencias."
      ],
      "metadata": {
        "id": "3mion1VVqOQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Unión de RDDs**\n",
        "\n",
        "Combina los elementos de dos RDDs distintos."
      ],
      "metadata": {
        "id": "kQ342qs-qVMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([4, 5, 6])\n",
        "resultado = rdd1.union(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v23xa7nx9aa",
        "outputId": "6239b46b-1efb-4de0-c9f8-8260767a5f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Intersección de RDDs**\n",
        "\n",
        "Obtiene los elementos comunes entre dos RDDs."
      ],
      "metadata": {
        "id": "2-1zdPUjqYVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3, 4])\n",
        "rdd2 = sc.parallelize([3, 4, 5, 6])\n",
        "resultado = rdd1.intersection(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ8BbEOLyDCx",
        "outputId": "fa3f403f-1f98-4ae0-b99d-b652aed6d13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **Diferencia de RDDs**\n",
        "\n",
        "Obtiene los elementos que están en un RDD pero no en otro."
      ],
      "metadata": {
        "id": "VUW-E2_LqdMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3, 4])\n",
        "rdd2 = sc.parallelize([3, 4, 5, 6])\n",
        "resultado = rdd1.subtract(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNbD8eUyVca",
        "outputId": "ba569bd6-5d96-4780-eedf-9820f3f1906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. Transformaciones basadas en estructuras de datos\n",
        "\n",
        "Estas transformaciones permiten manipular los datos basados en su estructura."
      ],
      "metadata": {
        "id": "XSDAjvSxszu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Agrupación de elementos**\n",
        "\n",
        "Se agrupan elementos utilizando `groupByKey`."
      ],
      "metadata": {
        "id": "iByoz36Zs4Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd.groupByKey().mapValues(list)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "576FuMWEykwi",
        "outputId": "f0175485-4071-4349-a446-259cb7fd8042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', [2, 4]), ('a', [1, 3])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Ordenar elementos**\n",
        "\n",
        "Se pueden ordenar los datos por clave usando `sortByKey`."
      ],
      "metadata": {
        "id": "IsDAev-3s-FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(2, \"dos\"), (1, \"uno\"), (3, \"tres\")])\n",
        "resultado = rdd.sortByKey()\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYd50w0yooB",
        "outputId": "218f4cef-cd2a-48e6-e7c8-b16c3191fbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'uno'), (2, 'dos'), (3, 'tres')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 5. Funciones adicionales\n",
        "\n",
        "### a. **coalesce**\n",
        "\n",
        "Reduce el número de particiones en un RDD para optimizar el rendimiento y ahorrar memoria. Es útil para disminuir particiones al escribir datos en disco.\n",
        "\n",
        "**Nota:** Esta operación es muy costosa porque implica mover datos entre nodos y redistribuir las particiones. Por ello, es recomendable minimizar su uso siempre que sea posible."
      ],
      "metadata": {
        "id": "pmQHp5LEtc8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8], 4)\n",
        "resultado = rdd.coalesce(2)\n",
        "print(resultado.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpro8EaOy3qp",
        "outputId": "4666c8d6-e32e-4cf8-8293-629a705224d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **repartition**\n",
        "\n",
        "Aumenta o disminuye el número de particiones de un RDD. A diferencia de `coalesce`, permite el reparto uniforme de los datos a través de un shuffle.\n",
        "\n",
        "**Nota:** `repartition` también es una operación costosa, ya que involucra un shuffle completo de los datos en la red, lo que puede impactar significativamente el rendimiento. Es preferible planificar adecuadamente las particiones iniciales para evitar su uso."
      ],
      "metadata": {
        "id": "sJrIT5VctFCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8], 2)\n",
        "resultado = rdd.repartition(4)\n",
        "print(resultado.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshWlhHYzEJy",
        "outputId": "8e82ccba-a65a-423f-938d-f99c5fa406d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **distinct**\n",
        "\n",
        "Elimina los duplicados en un RDD."
      ],
      "metadata": {
        "id": "mn7XQQU-tJ8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 2, 3, 4, 4, 5])\n",
        "resultado = rdd.distinct()\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45zX6urUzMLR",
        "outputId": "9fbd1f92-46b8-403c-9f74-0718d95fc1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 1, 3, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. **sample**\n",
        "\n",
        "Extrae una muestra aleatoria de los datos en un RDD."
      ],
      "metadata": {
        "id": "GRXUN4QutqS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "resultado = rdd.sample(False, 0.3)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NryLGcGzRb5",
        "outputId": "0daaa1e0-c5f9-4418-dbe8-e8f228e49f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. **cartesian**\n",
        "\n",
        "Realiza el producto cartesiano entre dos RDDs."
      ],
      "metadata": {
        "id": "ONnj60-JttcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
        "resultado = rdd1.cartesian(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJFe7nagzhoY",
        "outputId": "aafb404b-2433-483c-89a6-bf2f255b2e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (3, 'a'), (2, 'b'), (2, 'c'), (3, 'b'), (3, 'c')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f. **zip**\n",
        "\n",
        "Combina dos RDDs en un par (clave, valor)."
      ],
      "metadata": {
        "id": "Tgm9khDqtx4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
        "resultado = rdd1.zip(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0MXBQ96z_Vo",
        "outputId": "f702ff2a-644a-49ad-9323-9054bdd1fda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'a'), (2, 'b'), (3, 'c')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### g. **mapPartitions**\n",
        "\n",
        "Aplica una función a cada partición completa en lugar de cada elemento individual, útil para optimizaciones."
      ],
      "metadata": {
        "id": "FeMu0dN0t1oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9], 3)\n",
        "\n",
        "# Definir una función que procese cada partición\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partición por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLtRpubT0UYi",
        "outputId": "449141f4-da4f-48a3-e984-44dd01b1abcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZyXkFbYe2JDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### h. **glom**\n",
        "\n",
        "Convierte cada partición de un RDD en una lista. El resultado es un nuevo RDD donde cada elemento representa una partición original como una lista. Esto te permite ver cómo están distribuidos los datos en cada partición o realizar operaciones específicas en las particiones completas."
      ],
      "metadata": {
        "id": "fOuUy1gE2MJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 4)\n",
        "\n",
        "# Mostrar los elementos de cada partición\n",
        "print(\"Elementos en cada partición:\", rdd.glom().collect())\n",
        "print(\"Elementos en partición 0:\", rdd.glom().collect()[0][1])\n",
        "print(\"Elementos en partición 0:\", rdd.glom().collect()[1:3])\n",
        "\n",
        "\n",
        "# Definir una función que procese cada partición\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partición por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(\"Resultado procesado:\", resultado.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4_fJ5_D1bdI",
        "outputId": "8ad305bf-a1e8-4dd6-ec18-7888955f6004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en cada partición: [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
            "Elementos en partición 0: 2\n",
            "Elementos en partición 0: [[4, 5, 6], [7, 8, 9]]\n",
            "Resultado procesado: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 4)\n",
        "\n",
        "# Obtener todas las particiones\n",
        "particiones = rdd.glom().collect()\n",
        "\n",
        "# Mostrar las particiones 0 y 3\n",
        "print(\"Elementos en cada partición:\", [particiones[0], particiones[3]])\n",
        "\n",
        "# Mostrar elementos de la partición 0\n",
        "print(\"Elementos en partición 0:\", particiones[0])\n",
        "\n",
        "# Mostrar elementos de la partición 3\n",
        "print(\"Elementos en partición 3:\", particiones[3])\n",
        "\n",
        "# Definir una función que procese cada partición\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partición por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(\"Resultado procesado:\", resultado.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxKaRmkJ6Jyf",
        "outputId": "6a159217-5714-4b4a-e510-061503e9da7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en cada partición: [[1, 2, 3], [10, 11, 12]]\n",
            "Elementos en partición 0: [1, 2, 3]\n",
            "Elementos en partición 3: [10, 11, 12]\n",
            "Resultado procesado: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UaB61aIXE373"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejercicios de Operaciones en los RDD:**\n",
        "\n",
        "# ⚡"
      ],
      "metadata": {
        "id": "1pxLXmafwydL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1. Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL.\n",
        "\n"
      ],
      "metadata": {
        "id": "P7iABFiAFGpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programación\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Mostrar el contenido del RDD\n",
        "print(lenguajes.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRT4guJVFkU2",
        "outputId": "fd3c2ead-2406-4350-9f2c-3bb9d6700409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. `Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programación estén en mayúsculas.`"
      ],
      "metadata": {
        "id": "Q5iQG7-PFm2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programación\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Crear un nuevo RDD con los lenguajes en mayúsculas\n",
        "lenguajes_mayusculas = lenguajes.map(lambda x: x.upper())\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_mayusculas.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygBEcW4FuMt",
        "outputId": "51b00948-2379-4777-903b-24ee37a5ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PYTHON', 'R', 'C', 'SCALA', 'RUGBY', 'SQL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. `Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programación estén en minúsculas.`"
      ],
      "metadata": {
        "id": "MQeOPmRLF3hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programación\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Crear un nuevo RDD con los lenguajes en minúsculas\n",
        "lenguajes_minusculas = lenguajes.map(lambda x: x.lower())\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_minusculas.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdC3TVxGB3u",
        "outputId": "a4e42bd2-e6fa-404a-9625-35b9cedf4a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['python', 'r', 'c', 'scala', 'rugby', 'sql']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " c. `Cree un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R.`"
      ],
      "metadata": {
        "id": "zVE7rfc_GLVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programación\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Filtrar los lenguajes que comienzan con la letra 'R'\n",
        "lenguajes_r = lenguajes.filter(lambda x: x.startswith('R'))\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_r.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNoYUB87GWHF",
        "outputId": "a33f5879-9f9e-4772-f830-d1e64efaea71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['R', 'Rugby']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30]."
      ],
      "metadata": {
        "id": "zxmrXB41G1k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'pares' con los números pares en el intervalo [20, 30]\n",
        "pares = sc.parallelize([x for x in range(20, 31) if x % 2 == 0])\n",
        "\n",
        "# Mostrar el contenido del RDD\n",
        "print(pares.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWjPafiEHOaF",
        "outputId": "85d24d90-41a6-4ab0-ed89-f6b7e1976893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 22, 24, 26, 28, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. `Cree el RDD llamado sqrt, este debe contener la raíz cuadrada de los elementos que componen el RDD pares.`"
      ],
      "metadata": {
        "id": "ZLarIVbnHcnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Crear el RDD 'sqrt' con la raíz cuadrada de cada elemento del RDD 'pares' redondeada a 3 decimales\n",
        "sqrt = pares.map(lambda x: round(math.sqrt(x), 3))\n",
        "\n",
        "# Mostrar el contenido del RDD 'sqrt'\n",
        "print(sqrt.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz95SFEBHyF0",
        "outputId": "e626db90-7a45-4875-8999-e50f6e89a11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.472, 4.69, 4.899, 5.099, 5.292, 5.477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. `Obtenga una lista compuesta por los números pares en el intervalo [20;30] y sus respectivas raíces cuadradas.`\n",
        "\n",
        "Un ejemplo del resultado deseado para el intervalo [50;60] sería la lista [50, 7.0710678118654755, 52, 7.211102550927978, 54, 7.3484692283495345, 56, 7.483314773547883, 58, 7.615773105863909, 60, 7.745966692414834]."
      ],
      "metadata": {
        "id": "dxG9RU_9ISQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la raíz cuadrada de los números pares y combinarlos en una lista alternada con dos decimales\n",
        "pares_y_sqrt = pares.map(lambda x: (x, round(math.sqrt(x), 2))).collect()\n",
        "\n",
        "# Aplanar la lista de tuplas para obtener una lista alternada (número, raíz cuadrada)\n",
        "resultado = [elem for pair in pares_y_sqrt for elem in pair]\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_izYp6ISrn",
        "outputId": "c74246db-00bc-41d0-d3bb-447f86870960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 4.47, 22, 4.69, 24, 4.9, 26, 5.1, 28, 5.29, 30, 5.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. `Eleve el número de particiones del RDD sqrt a 20.`"
      ],
      "metadata": {
        "id": "-PMR2oDGImOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elevar el número de particiones del RDD 'sqrt' a 20\n",
        "sqrt_con_20_particiones = sqrt.repartition(20)\n",
        "\n",
        "# Mostrar el número de particiones del nuevo RDD\n",
        "print(\"Número de particiones:\", sqrt_con_20_particiones.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNla7D9kItHd",
        "outputId": "1c34ebb4-b2a6-48c2-ab61-6d742e48571e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de particiones: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. `Si tuviera que disminuir el número de particiones luego de haberlo establecido en 20, ¿qué función utilizaría para hacer más eficiente su código?`"
      ],
      "metadata": {
        "id": "SYgA0cJsSSza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducir el número de particiones a 5 de manera eficiente\n",
        "sqrt_con_menos_particiones = sqrt.coalesce(5)\n",
        "\n",
        "# Mostrar el número de particiones del nuevo RDD\n",
        "print(\"Número de particiones después de reducir:\", sqrt_con_menos_particiones.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfbAhrbSZoz",
        "outputId": "f91d7fa9-fec8-4773-c31a-993578d6350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de particiones después de reducir: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Cree un RDD del tipo clave valor a partir de los datos adjuntos como recurso a esta lección. Tenga en cuenta que deberá procesar el RDD leído para obtener el resultado solicitado.\n",
        "\n",
        "Supongamos que el RDD resultante de tipo clave valor refleja las transacciones realizadas por número de cuentas. Obtenga el monto total por cada cuenta.\n",
        "\n",
        "`Data del Archivo:`\n",
        "\n",
        "(1001, 52.3)\n",
        "\n",
        "(1005, 20.8)\n",
        "\n",
        "(1001, 10.1)\n",
        "\n",
        "(1004, 52.7)\n",
        "\n",
        "(1005, 20.7)\n",
        "\n",
        "(1002, 85.3)\n",
        "\n",
        "(1004, 20.9)\n"
      ],
      "metadata": {
        "id": "I7OuAt5KTbMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo .txt en un RDD\n",
        "rdd = sc.textFile(\"/content/sample_data/transacciones\")\n",
        "\n",
        "# Convertir cada línea en una tupla (número de cuenta, monto) y crear el RDD de tipo clave-valor\n",
        "rdd_clave_valor = rdd.map(lambda x: eval(x))  # eval convierte la cadena '(1001, 52.3)' en una tupla\n",
        "\n",
        "# Sumar los montos por cuenta usando reduceByKey\n",
        "resultado = rdd_clave_valor.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Mostrar el resultado final (monto total por cada cuenta)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5hMuvwTbsS",
        "outputId": "ac9f1e07-f9e9-4c29-86cd-f21e1592bb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1004, 73.6), (1002, 85.3), (1001, 62.4), (1005, 41.5)]\n"
          ]
        }
      ]
    }
  ]
}