{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso a Paso Para Realizar Instalacion de Apache Spark en Colab**\n",
        "# **ü§Ø**\n",
        "---"
      ],
      "metadata": {
        "id": "aLApO7WKO3kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "z3COh-nXrene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Funci√≥n para instalar OpenJDK 8\n"
      ],
      "metadata": {
        "id": "dLWqeDnhldNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para instalar OpenJDK 8 si no est√° instalado previamente.\n",
        "def install_java():\n",
        "    # Verifica si la ruta del JDK existe.\n",
        "    if not os.path.exists('/usr/lib/jvm/java-8-openjdk-amd64'):\n",
        "        print(\"Instalando OpenJDK 8...\")\n",
        "        # Comando para instalar Java en modo silencioso.\n",
        "        !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "        print(\"OpenJDK 8 instalado correctamente.\")\n",
        "    else:\n",
        "        print(\"OpenJDK 8 ya est√° instalado.\")"
      ],
      "metadata": {
        "id": "ocwoPb91loee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Funci√≥n para descargar Apache Spark"
      ],
      "metadata": {
        "id": "avmuQpDIlrk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para descargar Apache Spark solo si no est√° ya descargado.\n",
        "def download_spark():\n",
        "    # URL y nombre del archivo comprimido de Spark.\n",
        "    spark_url = \"https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si el archivo comprimido ya existe.\n",
        "    if not os.path.exists(spark_tar):\n",
        "        print(\"Descargando Apache Spark...\")\n",
        "        # Comando para descargar el archivo desde la URL.\n",
        "        !wget -q $spark_url\n",
        "        print(\"Descarga completa.\")\n",
        "    else:\n",
        "        print(\"El archivo de Apache Spark ya est√° descargado.\")"
      ],
      "metadata": {
        "id": "Wt6hZEyulx52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Funci√≥n para descomprimir Apache Spark"
      ],
      "metadata": {
        "id": "8Jgxtdhal1MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para descomprimir el archivo de Apache Spark solo si no est√° descomprimido.\n",
        "def extract_spark():\n",
        "    # Nombre de la carpeta descomprimida.\n",
        "    spark_dir = \"spark-3.4.3-bin-hadoop3\"\n",
        "    spark_tar = \"spark-3.4.3-bin-hadoop3.tgz\"\n",
        "\n",
        "    # Verifica si la carpeta descomprimida ya existe.\n",
        "    if not os.path.exists(spark_dir):\n",
        "        print(\"Descomprimiendo Apache Spark...\")\n",
        "        # Comando para descomprimir el archivo.\n",
        "        !tar xf $spark_tar\n",
        "        print(\"Apache Spark descomprimido.\")\n",
        "    else:\n",
        "        print(\"La carpeta de Apache Spark ya existe.\")"
      ],
      "metadata": {
        "id": "ixXnx5VBl5mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Funci√≥n para configurar variables de entorno"
      ],
      "metadata": {
        "id": "CUL79waXl8G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para configurar las variables de entorno necesarias para Spark.\n",
        "def set_environment_variables():\n",
        "    # Establece la ruta de JAVA_HOME y SPARK_HOME.\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\"\n",
        "    print(\"Variables de entorno configuradas.\")"
      ],
      "metadata": {
        "id": "9Z1obZ1al_Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Funci√≥n para verificar si un paquete est√° instalado"
      ],
      "metadata": {
        "id": "5lZztVgNmErm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para verificar si un paquete de Python ya est√° instalado.\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def is_package_installed(package_name):\n",
        "    try:\n",
        "        # Ejecuta el comando `pip show` para verificar si el paquete est√° instalado.\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"show\", package_name],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL\n",
        "        )\n",
        "        return True\n",
        "    except subprocess.CalledProcessError:\n",
        "        return False"
      ],
      "metadata": {
        "id": "l7iVbLSFmL_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Funci√≥n para instalar findspark y pyspark"
      ],
      "metadata": {
        "id": "pGJ6jvDVmSBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para instalar librer√≠as de Python necesarias (findspark y pyspark).\n",
        "def install_python_libraries():\n",
        "    # Verifica e instala findspark.\n",
        "    if not is_package_installed(\"findspark\"):\n",
        "        print(\"Instalando findspark...\")\n",
        "        !pip install -q findspark\n",
        "    else:\n",
        "        print(\"findspark ya est√° instalado.\")\n",
        "\n",
        "    # Verifica e instala pyspark.\n",
        "    if not is_package_installed(\"pyspark\"):\n",
        "        print(\"Instalando pyspark...\")\n",
        "        !pip install -q pyspark\n",
        "    else:\n",
        "        print(\"pyspark ya est√° instalado.\")"
      ],
      "metadata": {
        "id": "iFauCFnDmT7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Llamar a las funciones**"
      ],
      "metadata": {
        "id": "5aOgcvM-mZam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install_java()                # Instala OpenJDK 8\n",
        "download_spark()              # Descarga Apache Spark\n",
        "extract_spark()               # Descomprime Apache Spark\n",
        "set_environment_variables()   # Configura las variables de entorno\n",
        "install_python_libraries()    # Instala las librer√≠as de Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9NdiQLAmfPW",
        "outputId": "8745a976-d8d8-49aa-e6d8-988c90fa992f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenJDK 8 ya est√° instalado.\n",
            "El archivo de Apache Spark ya est√° descargado.\n",
            "La carpeta de Apache Spark ya existe.\n",
            "Variables de entorno configuradas.\n",
            "findspark ya est√° instalado.\n",
            "pyspark ya est√° instalado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "O24lzVStmn72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Verificar la Instalacion"
      ],
      "metadata": {
        "id": "qZTO7-eNaT0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la biblioteca findspark\n",
        "import findspark\n",
        "\n",
        "# Inicializamos findspark para configurar las rutas necesarias para Spark\n",
        "findspark.init()\n",
        "\n",
        "# Importamos SparkSession desde pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Creamos una instancia de SparkSession\n",
        "# - `master(\"local[*]\")`: Ejecuta Spark en modo local usando todos los n√∫cleos disponibles.\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "LFws1CIIVcVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo con varias columnas\n",
        "# - `datos`: Es una lista de tuplas, donde cada tupla representa una fila del DataFrame.\n",
        "# - `columnas`: Especifica los nombres de las columnas.\n",
        "datos = [\n",
        "    (\"Jorge Luis\", 46, \"Cient√≠fico de Datos\"),\n",
        "    (\"Maria Gabriela\", 41, \"Administrador\"),\n",
        "    (\"Barbara\", 10, \"Pintor\"),\n",
        "    (\"Marco Antonio\", 5, \"Pre-Esccolar\"),\n",
        "    (\"Luis\", 74, \"Escritor\")\n",
        "]\n",
        "columnas = [\"Nombre\", \"Edad\", \"Profesi√≥n\"]\n",
        "\n",
        "# Creamos el DataFrame utilizando los datos y las columnas especificadas\n",
        "df = spark.createDataFrame(datos, columnas)\n",
        "\n",
        "# Mostramos el contenido del DataFrame\n",
        "# - `show()`: Muestra las primeras filas del DataFrame.\n",
        "# - `truncate=False`: Evita truncar los valores largos en las columnas.\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Ru8UsGXFZA",
        "outputId": "bf231364-6b2a-4fd0-de43-ea08ab9c76e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+-------------------+\n",
            "|Nombre        |Edad|Profesi√≥n          |\n",
            "+--------------+----+-------------------+\n",
            "|Jorge Luis    |46  |Cient√≠fico de Datos|\n",
            "|Maria Gabriela|41  |Administrador      |\n",
            "|Barbara       |10  |Pintor             |\n",
            "|Marco Antonio |5   |Pre-Esccolar       |\n",
            "|Luis          |74  |Escritor           |\n",
            "+--------------+----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëå üÜó **Culminado**\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "3GIDgjm2o_CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operaciones principales en RDD**\n",
        "\n",
        "# üîñ"
      ],
      "metadata": {
        "id": "kP5vxailckCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducci√≥n\n",
        "\n",
        "Un Resilient Distributed Dataset (RDD) en Apache Spark es una colecci√≥n distribuida de elementos que puede ser procesada en paralelo. Los RDD ofrecen dos tipos principales de operaciones: transformaciones y acciones. En este documento, nos enfocaremos en las transformaciones y las clasificaremos en diferentes categor√≠as seg√∫n su naturaleza.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "O4_lkmLOoOEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Iniciar Sesion de Spark\""
      ],
      "metadata": {
        "id": "IH8lZhVavyNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "n3OoxqsgvoWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 1. Transformaciones generales\n",
        "\n",
        "Las transformaciones generales permiten modificar o reorganizar los datos dentro de un RDD. Estas incluyen:"
      ],
      "metadata": {
        "id": "xBsNHx0UwBby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Dividir los elementos de entrada**\n",
        "\n",
        "Esta transformaci√≥n se utiliza para dividir los elementos de un RDD en subcomponentes. Una operaci√≥n com√∫n es `flatMap`, que genera m√∫ltiples salidas para cada entrada."
      ],
      "metadata": {
        "id": "RaAkbrNYomz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([\"hola mundo\", \"aprendiendo Spark\", \"RDD en acci√≥n\"])\n",
        "resultado = rdd.flatMap(lambda linea: linea.split(\" \"))\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kRHRx7duXrp",
        "outputId": "f896e633-ad88-4f4e-e4d6-1e51f06887b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'mundo', 'aprendiendo', 'Spark', 'RDD', 'en', 'acci√≥n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Filtrar elementos**\n",
        "\n",
        "La operaci√≥n `filter` permite seleccionar s√≥lo los elementos que cumplen una condici√≥n determinada."
      ],
      "metadata": {
        "id": "bngLC75YpETF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "resultado = rdd.filter(lambda x: x % 2 == 0)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhTFquoNxGUb",
        "outputId": "244f1a13-d8ba-44a8-daa3-4a7a7b2f4a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **Realizar c√°lculos**\n",
        "\n",
        "Se pueden realizar transformaciones matem√°ticas como operaciones aritm√©ticas utilizando `map`."
      ],
      "metadata": {
        "id": "-jviueaJpJNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "resultado = rdd.map(lambda x: x ** 2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Hj_oCdxKsJ",
        "outputId": "4173a6c3-4e31-460d-fecc-5be080e95acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4vdHmsDwpqIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Transformaciones matem√°ticas\n",
        "\n",
        "Estas transformaciones est√°n dise√±adas para realizar operaciones aritm√©ticas o algebraicas sobre los datos."
      ],
      "metadata": {
        "id": "AZ242Dq0p7IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Suma acumulativa**\n",
        "\n",
        "Utilizando `reduceByKey`, se puede sumar valores asociados con claves espec√≠ficas."
      ],
      "metadata": {
        "id": "dq3hvzvNqDZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd.reduceByKey(lambda x, y: x + y)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKZysqftxWUg",
        "outputId": "83c7c11e-6dec-42bc-b27d-3bff1539e94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 6), ('a', 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **C√°lculo promedio**\n",
        "\n",
        "Podemos calcular el promedio agrupando valores por clave y dividiendo la suma por el conteo."
      ],
      "metadata": {
        "id": "3O98-jXrqGuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd\\\n",
        "    .mapValues(lambda x: (x, 1))\\\n",
        "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
        "    .mapValues(lambda x: x[0] / x[1])\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I3B_niBxb0C",
        "outputId": "f2f73ef8-4857-48ee-b0f2-2abac17cb4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 3.0), ('a', 2.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. Transformaciones de conjunto o relacionales\n",
        "\n",
        "Estas transformaciones operan en conjuntos de datos y se utilizan para relaciones como uniones, intersecciones o diferencias."
      ],
      "metadata": {
        "id": "3mion1VVqOQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Uni√≥n de RDDs**\n",
        "\n",
        "Combina los elementos de dos RDDs distintos."
      ],
      "metadata": {
        "id": "kQ342qs-qVMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([4, 5, 6])\n",
        "resultado = rdd1.union(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v23xa7nx9aa",
        "outputId": "6239b46b-1efb-4de0-c9f8-8260767a5f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Intersecci√≥n de RDDs**\n",
        "\n",
        "Obtiene los elementos comunes entre dos RDDs."
      ],
      "metadata": {
        "id": "2-1zdPUjqYVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3, 4])\n",
        "rdd2 = sc.parallelize([3, 4, 5, 6])\n",
        "resultado = rdd1.intersection(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ8BbEOLyDCx",
        "outputId": "fa3f403f-1f98-4ae0-b99d-b652aed6d13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **Diferencia de RDDs**\n",
        "\n",
        "Obtiene los elementos que est√°n en un RDD pero no en otro."
      ],
      "metadata": {
        "id": "VUW-E2_LqdMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3, 4])\n",
        "rdd2 = sc.parallelize([3, 4, 5, 6])\n",
        "resultado = rdd1.subtract(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNbD8eUyVca",
        "outputId": "ba569bd6-5d96-4780-eedf-9820f3f1906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. Transformaciones basadas en estructuras de datos\n",
        "\n",
        "Estas transformaciones permiten manipular los datos basados en su estructura."
      ],
      "metadata": {
        "id": "XSDAjvSxszu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. **Agrupaci√≥n de elementos**\n",
        "\n",
        "Se agrupan elementos utilizando `groupByKey`."
      ],
      "metadata": {
        "id": "iByoz36Zs4Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
        "resultado = rdd.groupByKey().mapValues(list)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "576FuMWEykwi",
        "outputId": "f0175485-4071-4349-a446-259cb7fd8042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', [2, 4]), ('a', [1, 3])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **Ordenar elementos**\n",
        "\n",
        "Se pueden ordenar los datos por clave usando `sortByKey`."
      ],
      "metadata": {
        "id": "IsDAev-3s-FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([(2, \"dos\"), (1, \"uno\"), (3, \"tres\")])\n",
        "resultado = rdd.sortByKey()\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYd50w0yooB",
        "outputId": "218f4cef-cd2a-48e6-e7c8-b16c3191fbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'uno'), (2, 'dos'), (3, 'tres')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 5. Funciones adicionales\n",
        "\n",
        "### a. **coalesce**\n",
        "\n",
        "Reduce el n√∫mero de particiones en un RDD para optimizar el rendimiento y ahorrar memoria. Es √∫til para disminuir particiones al escribir datos en disco.\n",
        "\n",
        "**Nota:** Esta operaci√≥n es muy costosa porque implica mover datos entre nodos y redistribuir las particiones. Por ello, es recomendable minimizar su uso siempre que sea posible."
      ],
      "metadata": {
        "id": "pmQHp5LEtc8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8], 4)\n",
        "resultado = rdd.coalesce(2)\n",
        "print(resultado.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpro8EaOy3qp",
        "outputId": "4666c8d6-e32e-4cf8-8293-629a705224d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. **repartition**\n",
        "\n",
        "Aumenta o disminuye el n√∫mero de particiones de un RDD. A diferencia de `coalesce`, permite el reparto uniforme de los datos a trav√©s de un shuffle.\n",
        "\n",
        "**Nota:** `repartition` tambi√©n es una operaci√≥n costosa, ya que involucra un shuffle completo de los datos en la red, lo que puede impactar significativamente el rendimiento. Es preferible planificar adecuadamente las particiones iniciales para evitar su uso."
      ],
      "metadata": {
        "id": "sJrIT5VctFCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8], 2)\n",
        "resultado = rdd.repartition(4)\n",
        "print(resultado.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshWlhHYzEJy",
        "outputId": "8e82ccba-a65a-423f-938d-f99c5fa406d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. **distinct**\n",
        "\n",
        "Elimina los duplicados en un RDD."
      ],
      "metadata": {
        "id": "mn7XQQU-tJ8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 2, 3, 4, 4, 5])\n",
        "resultado = rdd.distinct()\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45zX6urUzMLR",
        "outputId": "9fbd1f92-46b8-403c-9f74-0718d95fc1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 1, 3, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. **sample**\n",
        "\n",
        "Extrae una muestra aleatoria de los datos en un RDD."
      ],
      "metadata": {
        "id": "GRXUN4QutqS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "resultado = rdd.sample(False, 0.3)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NryLGcGzRb5",
        "outputId": "0daaa1e0-c5f9-4418-dbe8-e8f228e49f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. **cartesian**\n",
        "\n",
        "Realiza el producto cartesiano entre dos RDDs."
      ],
      "metadata": {
        "id": "ONnj60-JttcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
        "resultado = rdd1.cartesian(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJFe7nagzhoY",
        "outputId": "aafb404b-2433-483c-89a6-bf2f255b2e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (3, 'a'), (2, 'b'), (2, 'c'), (3, 'b'), (3, 'c')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f. **zip**\n",
        "\n",
        "Combina dos RDDs en un par (clave, valor)."
      ],
      "metadata": {
        "id": "Tgm9khDqtx4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.parallelize([1, 2, 3])\n",
        "rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
        "resultado = rdd1.zip(rdd2)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0MXBQ96z_Vo",
        "outputId": "f702ff2a-644a-49ad-9323-9054bdd1fda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'a'), (2, 'b'), (3, 'c')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### g. **mapPartitions**\n",
        "\n",
        "Aplica una funci√≥n a cada partici√≥n completa en lugar de cada elemento individual, √∫til para optimizaciones."
      ],
      "metadata": {
        "id": "FeMu0dN0t1oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9], 3)\n",
        "\n",
        "# Definir una funci√≥n que procese cada partici√≥n\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partici√≥n por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLtRpubT0UYi",
        "outputId": "449141f4-da4f-48a3-e984-44dd01b1abcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZyXkFbYe2JDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### h. **glom**\n",
        "\n",
        "Convierte cada partici√≥n de un RDD en una lista. El resultado es un nuevo RDD donde cada elemento representa una partici√≥n original como una lista. Esto te permite ver c√≥mo est√°n distribuidos los datos en cada partici√≥n o realizar operaciones espec√≠ficas en las particiones completas."
      ],
      "metadata": {
        "id": "fOuUy1gE2MJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 4)\n",
        "\n",
        "# Mostrar los elementos de cada partici√≥n\n",
        "print(\"Elementos en cada partici√≥n:\", rdd.glom().collect())\n",
        "print(\"Elementos en partici√≥n 0:\", rdd.glom().collect()[0][1])\n",
        "print(\"Elementos en partici√≥n 0:\", rdd.glom().collect()[1:3])\n",
        "\n",
        "\n",
        "# Definir una funci√≥n que procese cada partici√≥n\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partici√≥n por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(\"Resultado procesado:\", resultado.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4_fJ5_D1bdI",
        "outputId": "8ad305bf-a1e8-4dd6-ec18-7888955f6004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en cada partici√≥n: [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
            "Elementos en partici√≥n 0: 2\n",
            "Elementos en partici√≥n 0: [[4, 5, 6], [7, 8, 9]]\n",
            "Resultado procesado: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 4)\n",
        "\n",
        "# Obtener todas las particiones\n",
        "particiones = rdd.glom().collect()\n",
        "\n",
        "# Mostrar las particiones 0 y 3\n",
        "print(\"Elementos en cada partici√≥n:\", [particiones[0], particiones[3]])\n",
        "\n",
        "# Mostrar elementos de la partici√≥n 0\n",
        "print(\"Elementos en partici√≥n 0:\", particiones[0])\n",
        "\n",
        "# Mostrar elementos de la partici√≥n 3\n",
        "print(\"Elementos en partici√≥n 3:\", particiones[3])\n",
        "\n",
        "# Definir una funci√≥n que procese cada partici√≥n\n",
        "def procesar_particion(particion):\n",
        "    # Multiplicar cada elemento de la partici√≥n por 2\n",
        "    return (x * 2 for x in particion)\n",
        "\n",
        "# Aplicar mapPartitions al RDD\n",
        "resultado = rdd.mapPartitions(procesar_particion)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(\"Resultado procesado:\", resultado.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxKaRmkJ6Jyf",
        "outputId": "6a159217-5714-4b4a-e510-061503e9da7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en cada partici√≥n: [[1, 2, 3], [10, 11, 12]]\n",
            "Elementos en partici√≥n 0: [1, 2, 3]\n",
            "Elementos en partici√≥n 3: [10, 11, 12]\n",
            "Resultado procesado: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UaB61aIXE373"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejercicios de Operaciones en los RDD:**\n",
        "\n",
        "# ‚ö°"
      ],
      "metadata": {
        "id": "1pxLXmafwydL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1. Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programaci√≥n: Python, R, C, Scala, Rugby y SQL.\n",
        "\n"
      ],
      "metadata": {
        "id": "P7iABFiAFGpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programaci√≥n\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Mostrar el contenido del RDD\n",
        "print(lenguajes.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRT4guJVFkU2",
        "outputId": "fd3c2ead-2406-4350-9f2c-3bb9d6700409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. `Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programaci√≥n est√©n en may√∫sculas.`"
      ],
      "metadata": {
        "id": "Q5iQG7-PFm2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programaci√≥n\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Crear un nuevo RDD con los lenguajes en may√∫sculas\n",
        "lenguajes_mayusculas = lenguajes.map(lambda x: x.upper())\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_mayusculas.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygBEcW4FuMt",
        "outputId": "51b00948-2379-4777-903b-24ee37a5ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PYTHON', 'R', 'C', 'SCALA', 'RUGBY', 'SQL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. `Obtenga un nuevo RDD a partir del RDD lenguajes donde todos los lenguajes de programaci√≥n est√©n en min√∫sculas.`"
      ],
      "metadata": {
        "id": "MQeOPmRLF3hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programaci√≥n\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Crear un nuevo RDD con los lenguajes en min√∫sculas\n",
        "lenguajes_minusculas = lenguajes.map(lambda x: x.lower())\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_minusculas.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdC3TVxGB3u",
        "outputId": "a4e42bd2-e6fa-404a-9625-35b9cedf4a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['python', 'r', 'c', 'scala', 'rugby', 'sql']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " c. `Cree un nuevo RDD que solo contenga aquellos lenguajes de programaci√≥n que comiencen con la letra R.`"
      ],
      "metadata": {
        "id": "zVE7rfc_GLVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'lenguajes' con los lenguajes de programaci√≥n\n",
        "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
        "\n",
        "# Filtrar los lenguajes que comienzan con la letra 'R'\n",
        "lenguajes_r = lenguajes.filter(lambda x: x.startswith('R'))\n",
        "\n",
        "# Mostrar el contenido del nuevo RDD\n",
        "print(lenguajes_r.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNoYUB87GWHF",
        "outputId": "a33f5879-9f9e-4772-f830-d1e64efaea71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['R', 'Rugby']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cree un RDD llamado pares que contenga los n√∫meros pares existentes en el intervalo [20;30]."
      ],
      "metadata": {
        "id": "zxmrXB41G1k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el RDD 'pares' con los n√∫meros pares en el intervalo [20, 30]\n",
        "pares = sc.parallelize([x for x in range(20, 31) if x % 2 == 0])\n",
        "\n",
        "# Mostrar el contenido del RDD\n",
        "print(pares.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWjPafiEHOaF",
        "outputId": "85d24d90-41a6-4ab0-ed89-f6b7e1976893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 22, 24, 26, 28, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. `Cree el RDD llamado sqrt, este debe contener la ra√≠z cuadrada de los elementos que componen el RDD pares.`"
      ],
      "metadata": {
        "id": "ZLarIVbnHcnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Crear el RDD 'sqrt' con la ra√≠z cuadrada de cada elemento del RDD 'pares' redondeada a 3 decimales\n",
        "sqrt = pares.map(lambda x: round(math.sqrt(x), 3))\n",
        "\n",
        "# Mostrar el contenido del RDD 'sqrt'\n",
        "print(sqrt.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz95SFEBHyF0",
        "outputId": "e626db90-7a45-4875-8999-e50f6e89a11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.472, 4.69, 4.899, 5.099, 5.292, 5.477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. `Obtenga una lista compuesta por los n√∫meros pares en el intervalo [20;30] y sus respectivas ra√≠ces cuadradas.`\n",
        "\n",
        "Un ejemplo del resultado deseado para el intervalo [50;60] ser√≠a la lista [50, 7.0710678118654755, 52, 7.211102550927978, 54, 7.3484692283495345, 56, 7.483314773547883, 58, 7.615773105863909, 60, 7.745966692414834]."
      ],
      "metadata": {
        "id": "dxG9RU_9ISQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la ra√≠z cuadrada de los n√∫meros pares y combinarlos en una lista alternada con dos decimales\n",
        "pares_y_sqrt = pares.map(lambda x: (x, round(math.sqrt(x), 2))).collect()\n",
        "\n",
        "# Aplanar la lista de tuplas para obtener una lista alternada (n√∫mero, ra√≠z cuadrada)\n",
        "resultado = [elem for pair in pares_y_sqrt for elem in pair]\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_izYp6ISrn",
        "outputId": "c74246db-00bc-41d0-d3bb-447f86870960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 4.47, 22, 4.69, 24, 4.9, 26, 5.1, 28, 5.29, 30, 5.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. `Eleve el n√∫mero de particiones del RDD sqrt a 20.`"
      ],
      "metadata": {
        "id": "-PMR2oDGImOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elevar el n√∫mero de particiones del RDD 'sqrt' a 20\n",
        "sqrt_con_20_particiones = sqrt.repartition(20)\n",
        "\n",
        "# Mostrar el n√∫mero de particiones del nuevo RDD\n",
        "print(\"N√∫mero de particiones:\", sqrt_con_20_particiones.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNla7D9kItHd",
        "outputId": "1c34ebb4-b2a6-48c2-ab61-6d742e48571e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de particiones: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. `Si tuviera que disminuir el n√∫mero de particiones luego de haberlo establecido en 20, ¬øqu√© funci√≥n utilizar√≠a para hacer m√°s eficiente su c√≥digo?`"
      ],
      "metadata": {
        "id": "SYgA0cJsSSza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducir el n√∫mero de particiones a 5 de manera eficiente\n",
        "sqrt_con_menos_particiones = sqrt.coalesce(5)\n",
        "\n",
        "# Mostrar el n√∫mero de particiones del nuevo RDD\n",
        "print(\"N√∫mero de particiones despu√©s de reducir:\", sqrt_con_menos_particiones.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfbAhrbSZoz",
        "outputId": "f91d7fa9-fec8-4773-c31a-993578d6350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de particiones despu√©s de reducir: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Cree un RDD del tipo clave valor a partir de los datos adjuntos como recurso a esta lecci√≥n. Tenga en cuenta que deber√° procesar el RDD le√≠do para obtener el resultado solicitado.\n",
        "\n",
        "Supongamos que el RDD resultante de tipo clave valor refleja las transacciones realizadas por n√∫mero de cuentas. Obtenga el monto total por cada cuenta.\n",
        "\n",
        "`Data del Archivo:`\n",
        "\n",
        "(1001, 52.3)\n",
        "\n",
        "(1005, 20.8)\n",
        "\n",
        "(1001, 10.1)\n",
        "\n",
        "(1004, 52.7)\n",
        "\n",
        "(1005, 20.7)\n",
        "\n",
        "(1002, 85.3)\n",
        "\n",
        "(1004, 20.9)\n"
      ],
      "metadata": {
        "id": "I7OuAt5KTbMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo .txt en un RDD\n",
        "rdd = sc.textFile(\"/content/sample_data/transacciones\")\n",
        "\n",
        "# Convertir cada l√≠nea en una tupla (n√∫mero de cuenta, monto) y crear el RDD de tipo clave-valor\n",
        "rdd_clave_valor = rdd.map(lambda x: eval(x))  # eval convierte la cadena '(1001, 52.3)' en una tupla\n",
        "\n",
        "# Sumar los montos por cuenta usando reduceByKey\n",
        "resultado = rdd_clave_valor.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Mostrar el resultado final (monto total por cada cuenta)\n",
        "print(resultado.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5hMuvwTbsS",
        "outputId": "ac9f1e07-f9e9-4c29-86cd-f21e1592bb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1004, 73.6), (1002, 85.3), (1001, 62.4), (1005, 41.5)]\n"
          ]
        }
      ]
    }
  ]
}